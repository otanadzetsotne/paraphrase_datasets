# Paraphrasing datasets


* **GLUE (General Language Understanding Evaluation benchmark)**

  [Home page ->](https://gluebenchmark.com/)

  [tensorflow ->](https://www.tensorflow.org/datasets/catalog/glue)

  [github ->](https://github.com/nyu-mll/GLUE-baselines)


* **MRPC (Microsoft Research Paraphrase Corpus)**

  The Microsoft Research Paraphrase Corpus (Dolan & Brockett, 2005) is a corpus of sentence pairs automatically retrieved from online news sources, with human annotations indicating whether the sentences in the pair are semantically equivalent.
    
  [Home page ->](https://www.microsoft.com/en-us/download/details.aspx?id=52398)

  [Download ->](https://download.microsoft.com/download/D/4/6/D46FF87A-F6B9-4252-AA8B-3604ED519838/MSRParaphraseCorpus.msi)


* **CoLA (The Corpus of Linguistic Acceptability)**

  The corpus of linguistic acceptability consists of judgments about the acceptability of the English language taken from books and journal articles on linguistic theory. Each example is a sequence of words annotated with whether it is grammatically an English sentence.  

  [Home page ->](https://nyu-mll.github.io/CoLA/)

  [Download ->](https://nyu-mll.github.io/CoLA/cola_public_1.1.zip)


* **QQP (Quora Question Pairs)**

  The Quora Question Pairs2 dataset is a collection of question pairs from the community question-answering website Quora. The task is to determine whether a pair of questions are semantically equivalent.

  [Kaggle ->](https://www.kaggle.com/competitions/quora-question-pairs)


* **STS (The Semantic Textual Similarity Benchmark)**

  The Semantic Textual Similarity Benchmark (Cer et al., 2017) is a collection of sentence pairs drawn from news headlines, video and image captions, and natural language inference data. Each pair is human-annotated with a similarity score from 0 to 5. 

  [Home page ->](http://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark)

  [Download ->](http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz)


* **PAWS (Paraphrase Adversaries from Word Scrambling)**

  This dataset contains 108,463 human-labeled and 656k noisily labeled pairs that feature the importance of modeling structure, context, and word order information for the problem of paraphrase identification. The dataset has two subsets, one based on Wikipedia and the other one based on the Quora Question Pairs (QQP) dataset.

  [paper ->](https://arxiv.org/abs/1904.01130)

  [github ->](https://github.com/google-research-datasets/paws)

  [Download (Wiki) (размеченный) ->](https://storage.googleapis.com/paws/english/paws_wiki_labeled_final.tar.gz)

  [Download (Wiki) (размеченный, только с перестановками) ->](https://storage.googleapis.com/paws/english/paws_wiki_labeled_swap.tar.gz)


* **PAWS-x**

  This dataset contains 23,659 human translated PAWS evaluation pairs and 296,406 machine translated training pairs in six typologically distinct languages: French, Spanish, German, Chinese, Japanese, and Korean. All translated pairs are sourced from examples in PAWS-Wiki.

  [github ->](https://github.com/google-research-datasets/paws/tree/master/pawsx)
  
  [Download ->](https://storage.googleapis.com/paws/pawsx/x-final.tar.gz)


* **PIT (Paraphrase and Semantic Similarity in Twitter)**

  Paraphrase and Semantic Similarity in Twitter (PIT) presents a constructed Twitter Paraphrase Corpus that contains 18,762 sentence pairs.

  [github ->](https://github.com/cocoxu/SemEval-PIT2015)


* **SciTail**

  The SciTail dataset is an entailment dataset created from multiple-choice science exams and web sentences. Each question and the correct answer choice are converted into an assertive statement to form the hypothesis.

  [Home page ->](https://allenai.org/data/scitail)

  [Paper ->](https://www.semanticscholar.org/paper/SciTaiL%3A-A-Textual-Entailment-Dataset-from-Science-Khot-Sabharwal/cf8c493079702ec420ab4fc9c0fabb56b2a16c84)

  [Download ->](https://ai2-public-datasets.s3.amazonaws.com/scitail/SciTailV1.1.zip)


* **TURL (Twitter News URL Corpus)**

  *Requires Access*

  Twitter News URL Corpus is a human-labeled paraphrase corpus to date of 51,524 sentence pairs and the first cross-domain benchmarking for automatic paraphrase identification.

  [github ->](https://github.com/lanwuwei/Twitter-URL-Corpus)


* **CQADupStack**

  CQADupStack is a benchmark dataset for community question-answering research. It contains threads from twelve StackExchange subforums, annotated with duplicate question information. Pre-defined training and test splits are provided, both for retrieval and classification experiments, to ensure maximum comparability between different studies using the set. Furthermore, it comes with a script to manipulate the data in various ways.

  [Home page ->](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)

  [github ->](https://github.com/D1Doris/CQADupStack)

  [Download ->](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/cqadupstack.tar.gz)


* **Paralex**

  Paralex learns from a collection of 18 million question-paraphrase pairs scraped from WikiAnswers.

  [Home page ->](http://knowitall.cs.washington.edu/paralex/)

  [Cкачать ->](http://knowitall.cs.washington.edu/paralex/wikianswers-paraphrases-1.0.tar.gz)


* **Benchmark for Neural Paraphrase Detection**

  This is a benchmark for neural paraphrase detection, to differentiate between original and machine-generated content.

  [Home page ->](https://zenodo.org/record/4621403#.Y8HKMuxByrN)

  [Download ->](https://zenodo.org/record/4621403/files/MPC.zip?download=1)

